lambda = 0.0001
print(lambda)
p_hat <- cvx_solver(y_init,
graph_attributes$Gamma,
lambda, p_norm="inf")
p_hat[which(p_hat <0)]=0
p_hat[neighbors]
p_hat[subject_0]
lambda
lambda = 0.0005
print(lambda)
p_hat <- cvx_solver(y_init,
graph_attributes$Gamma,
lambda, p_norm="inf")
p_hat[which(p_hat <0)]=0
p_hat[neighbors]
p_hat[subject_0]
p_hat
graph_attributes$Gamma
graph_attributes$Gamma[1,]
print(lambda)
p_hat <- cvx_solver(y_init,
graph_attributes$Gamma,
lambda, p_norm="inf")
p_hat[which(p_hat <0)]=0
p_hat[neighbors]
lambda
lambda = 0.001
print(lambda)
p_hat <- cvx_solver(y_init,
graph_attributes$Gamma,
lambda, p_norm="inf")
p_hat[which(p_hat <0)]=0
p_hat[neighbors]
p_hat[subject_0]
p_hat
p_hat[which(abs(p_hat) <1e-10)]=0
p_hat
p_hat[neighbors]
p_hat[subject_0]
lambda
lambda = 0.01
print(lambda)
p_hat <- cvx_solver(y_init,
graph_attributes$Gamma,
lambda, p_norm="inf")
p_hat[which(p_hat <0)]=0
p_hat[which(abs(p_hat) <1e-10)]=0
p_hat[neighbors]
p_hat[subject_0]
p_hat
lambda = 0.1
print(lambda)
p_hat <- cvx_solver(y_init,
graph_attributes$Gamma,
lambda, p_norm="inf")
p_hat[which(p_hat <0)]=0
p_hat[which(abs(p_hat) <1e-10)]=0
p_hat[neighbors]
p_hat[subject_0]
cvx_solver <- function(y_observed, Gamma, lambda, p_norm = 1){
n_nodes <- length(y_observed)
#print(n_edges)
#print(lambda)
subject_0 = which(y_observed!=0)
p <- Variable(n_nodes - 1)
constraints <- list(p >= 0, p <= 1, p[subject_0] == 1)
# Define the quadratic loss
loss <- sum((y_observed - p)^2) / n_nodes
# Define the L-1 norm term
l1_norm <- cvxr_norm(Gamma %*% p, p = p_norm)
# Define the objective
objective <- Minimize(loss + lambda * l1_norm)
# Formulate the problem
problem <- Problem(objective, constraints)
# Solve the problem
result_problem <- solve(problem)
# Get the optimal value of p
p_opt <- result_problem$getValue(p)
return(p_opt)
}
p_hat <- cvx_solver(y_init,
graph_attributes$Gamma,
lambda, p_norm="inf")
y_observed
Gamma
Gamma = graph_attributes$Gamma
Gamma
p_norm
p_norm = 1
n_nodes <- length(y_observed)
#print(n_edges)
#print(lambda)
subject_0 = which(y_observed!=0)
subject_0
#print(n_edges)
#print(lambda)
subject_0 = which(y_observed!=0)
p <- Variable(n_nodes)
constraints <- list(p >= 0, p <= 1, p[subject_0] == 1)
# Define the quadratic loss
loss <- sum((y_observed - p)^2) / n_nodes
# Define the L-1 norm term
l1_norm <- cvxr_norm(Gamma %*% p, p = p_norm)
# Define the objective
objective <- Minimize(loss + lambda * l1_norm)
# Formulate the problem
problem <- Problem(objective, constraints)
# Solve the problem
result_problem <- solve(problem)
# Get the optimal value of p
p_opt <- result_problem$getValue(p)
cvx_solver <- function(y_observed, Gamma, lambda, p_norm = 1){
n_nodes <- length(y_observed)
#print(n_edges)
#print(lambda)
subject_0 = which(y_observed!=0)
p <- Variable(n_nodes)
constraints <- list(p >= 0, p <= 1, p[subject_0] == 1)
# Define the quadratic loss
loss <- sum((y_observed - p)^2) / n_nodes
# Define the L-1 norm term
l1_norm <- cvxr_norm(Gamma %*% p, p = p_norm)
# Define the objective
objective <- Minimize(loss + lambda * l1_norm)
# Formulate the problem
problem <- Problem(objective, constraints)
# Solve the problem
result_problem <- solve(problem)
# Get the optimal value of p
p_opt <- result_problem$getValue(p)
return(p_opt)
}
p_hat <- cvx_solver(y_init,
graph_attributes$Gamma,
lambda, p_norm="inf")
p_hat
p_hat[which(p_hat <0)]=0
p_hat[which(abs(p_hat) <1e-10)]=0
p_hat[neighbors]
p_hat[subject_0]
p_hat[subject_0]
p_hat[subject_0]
p_hat[subject_0] * 10
source("~/Documents/epidemic_modelling/r/solvers/cvx_solver.R")
print(lambda)
p_hat <- cvx_solver(y_init,
graph_attributes$Gamma,
lambda, p_norm="inf")
p_hat[which(p_hat <0)]=0
p_hat[which(abs(p_hat) <1e-10)]=0
p_hat[neighbors]
p_hat[subject_0]
p_hat
p_hat[which(abs(p_hat) <1e-7)]=0
p_hat
neighbors <- as.numeric(neighborhood(g, nodes = c(subject_0), mindist=1)[[1]])
p_hat[neighbors]
neighbors
library(tidyverse)
library(igraph)
source("graph_utils.R")
source("experiments/evaluate_solution.R")
source("experiments/simulate_epidemic.R")
source("r/solvers/cvx_solver.R")
# Parameters
args <- commandArgs(trailingOnly = TRUE)
source("~/Documents/epidemic_modelling/debug_params.R")
# Create random graph
g <- sample_pa(n, power = power_pa, directed = FALSE)
if (do_plot) {
layout <- layout_with_fr(g)
plot(g, layout = layout, vertex.size = 4,
edge.arrow.size = 0, vertex.label = NA)
}
# Assign initial patients
y_init <- rep(0, n)
subject_0 <- sample(1:n, nb_init)
y_init[subject_0] <- 1
# Record statistics on the initial patients
d <- degree(g, v = subject_0,
mode = "total", loops = TRUE,
normalized = FALSE)
btw <- betweenness(g, v = subject_0)
cls <- closeness(g, v = subject_0)
d
neighbors <- as.numeric(neighborhood(g, nodes = c(subject_0), mindist=1)[[1]])
neighbors
print(neighbors)
graph_attributes$W[subject_0, neighbors]
state <- simulate_epidemic(graph_attributes$W,
y_init = y_init,
beta = beta_epid,
gamma = gamma_epid,
steps = steps,
heterogeneity_rates = heterogeneity_rates)
state
graph_attributes <- get_edge_incidence(g, state$beta_v, graph = "PA", weight=1)
graph_attributes
graph_attributes$W[subject_0, neighbors]
lambda = 0.01
p_hat <- cvx_solver(y_init,
graph_attributes$Gamma,
lambda, p_norm="inf")
p_hat
p_hat[which(p_hat <0)]=0
p_hat[which(abs(p_hat) <1e-7)]=0
p_hat[neighbors]
p_hat[subject_0]
p_hat <- cvx_solver(y_init,
graph_attributes$Gamma,
lambda, p_norm=1)
p_hat[which(p_hat <0)]=0
p_hat[which(abs(p_hat) <1e-7)]=0
p_hat[neighbors]
p_hat[subject_0]
res_temp <- evaluate_solution(state$y_observed,
p_hat,
state$true_p,
graph_attributes$Gamma)
p_hat[which(p_hat <0)]=0
p_hat[which(abs(p_hat) <1e-7)]=0
lambda =0.0001
p_norm = "inf"
print(lambda)
p_hat <- cvx_solver(y_init,
graph_attributes$Gamma,
lambda, p_norm=p_norm)
lambda
lambda = 1e-3
print(lambda)
p_hat <- cvx_solver(y_init,
graph_attributes$Gamma,
lambda, p_norm=p_norm)
p_norm = "inf"
print(lambda)
p_hat <- cvx_solver(y_init,
graph_attributes$Gamma,
lambda, p_norm=p_norm)
graph_attributes$Gamma
lambda = 0.01
p_hat <- cvx_solver(y_init,
graph_attributes$Gamma,
lambda, p_norm=p_norm)
p_hat[which(p_hat <0)]=0
p_hat[which(abs(p_hat) <1e-7)]=0
p_hat[neighbors]
p_hat[subject_0]
p_hat
neighbors2 <- as.numeric(neighborhood(g, order=2, nodes = c(subject_0), mindist=2)[[1]])
neighbors2
p_hat[neighbors2]
p_hat[neighbors]
p_hat[neighbors2]
p_hat[subject_0]
lambda
e
# Propagate solution
prop_sol <- propagate_solution(graph_attributes$W, p_hat, state$beta_v,
state$gamma_v, 20)
prop_sol
propagate_solution <- function(W, p_hat, beta_v, gamma_v, nb_steps) {
p_current <- p_hat
list_p <- vector("list", nb_steps)
for (it in 1:nb_steps){
prop_results <- propagate_one_step(W, as.numeric(p_current), beta_v, gamma_v)
p_current <- sapply(prop_results$true_p, function(x){min(max(x,0), 1)})
list_p[[it]] <- p_current
}
return(list_p)
}
# Propagate solution
prop_sol <- propagate_solution(graph_attributes$W, p_hat, state$beta_v,
state$gamma_v, 20)
prop_sol
# Propagate real data
prop_truth <- propagate_solution(graph_attributes$W, y_init,
state$beta_v, state$gamma_v, 20)
prop_truth
# Compare the two
for (it in 1:20){
res_temp[ paste0("l1_propagated_error_", it)] = mean(abs(prop_truth[[it]] - prop_sol[[it]]))
res_temp[ paste0("l2_propagated_error_", it)] = mean((prop_truth[[it]] - prop_sol[[it]])^2)
}
res_temp
library(tidyverse)
setwd("~/Documents/epidemic_modelling/experiments/results/pa_graph/")
setwd("~/Documents/epidemic_modelling/experiments/results/pa_graph/")
theme_set(theme_bw(base_size = 14))
folder_path <- "~/Documents/epidemic_modelling/experiments/results/pa_graph/"
file_list <- list.files(folder_path, full.names = TRUE)
file_list
file_list <- list.files(folder_path, pattern = "^9", full.names = TRUE)
#file_list <- c(file_list, list.files(folder_path, pattern = "^759", full.names = TRUE))
# Read all the files into a single data frame using map_dfr.
data <- map_dfr(file_list, read_csv)  # Assuming your files are CSV files. Adjust the function accordingly if they are different file types.
dim(data)
colnames(data)
unique(data$exp)
data_list <- lapply(file_list, function(file) {
data <- read.csv(file, stringsAsFactors = FALSE)
data$filename <- file
return(data)
})
# Combine all individual data frames into one data frame
data <- do.call(rbind, data_list)
colnames(data)
#### first group by experiment
res  = data %>%
group_by(filename, lambda, beta_epid, gamma_epid, n, power_pa, steps, heterogeneity_rates, nb_init, p_norm) %>%
summarise_all(mean)
dim(res)
###
res_all  = res %>%
select(-c("filename")) %>%
group_by(lambda, beta_epid, gamma_epid, n, power_pa, steps, heterogeneity_rates, nb_init, p_norm) %>%
summarise_all(mean)
res$heterogeneity_rates
res %>%
select(-c("filename"))
###
res_all  = res %>%
select(-c(`filename`)) %>%
group_by(lambda, beta_epid, gamma_epid, n, power_pa, steps, heterogeneity_rates, nb_init, p_norm) %>%
summarise_all(mean)
res %>%
select(-c(`filename`))
res %>%
select(-`filename`)
###
res_all  = res %>%
select(-`filename`) %>%
group_by(lambda, beta_epid, gamma_epid, n, power_pa, steps, heterogeneity_rates, nb_init, p_norm) %>%
summarise_all(mean)
res %>%
select(-`filename`)
res %>%
select(-filename)
res %>%
select(-`filename`)
res %>% ungroup() %>%
select(-`filename`)
###
res_all  = res %>%
ungroup() %>%
select(-`filename`) %>%
group_by(lambda, beta_epid, gamma_epid, n, power_pa, steps, heterogeneity_rates, nb_init, p_norm) %>%
summarise_all(mean)
res_all
dim(res_all)
unique(res_all$lambda)
unique(res_all$power_pa)
unique(res_all$p_norm)
unique(res_all$beta_epid)
colnames(res_all)
unique(res_all$nb_init)
ggplot(res_all %>% filter(power_pa==1), aes(x=lambda, l1_error))+
geom_line()+
facet_wrap(beta_epid/gamma_epid~p_norm)
ggplot(res_all %>% filter(power_pa==1.2), aes(x=lambda, l1_error))+
geom_line()+
facet_wrap(beta_epid/gamma_epid~p_norm)
ggplot(res_all %>% filter(power_pa==1.2,
nb_init == 1), aes(x=lambda, l1_error))+
geom_line()+
facet_wrap(beta_epid/gamma_epid~p_norm)
ggplot(res_all %>% filter(power_pa==1.2,
nb_init == 1), aes(x=lambda, l1_error))+
geom_line()+
scale_x_log10()+
facet_wrap(beta_epid/gamma_epid~p_norm)
ggplot(res_all %>% filter(power_pa==1.2,
nb_init == 1), aes(x=lambda, l2_error))+
geom_line()+
scale_x_log10()+
facet_wrap(beta_epid/gamma_epid~p_norm)
ggplot(res_all %>% filter(power_pa==1.2,
nb_init == 1), aes(x=lambda, l2_error))+
geom_line()+
scale_x_log10()+
scale_y_log10() +
facet_wrap(beta_epid/gamma_epid~p_norm)
ggplot(res_all %>% filter(power_pa==1.2,
nb_init == 10), aes(x=lambda, l2_error))+
geom_line()+
scale_x_log10()+
scale_y_log10() +
facet_wrap(beta_epid/gamma_epid~p_norm)
ggplot(res_all %>% filter(power_pa==1.2,
nb_init == 10), aes(x=lambda, l2_error))+
geom_line()+
scale_x_log10()+
scale_y_log10() +
facet_wrap(beta_epid/gamma_epid~p_norm)
ggplot(res_all %>% filter(power_pa==1.2,
nb_init == 1), aes(x=lambda, l2_error))+
geom_line()+
scale_x_log10()+
scale_y_log10() +
facet_wrap(beta_epid/gamma_epid~p_norm)
ggplot(res_all %>% filter(power_pa==1.2,
nb_init == 1), aes(x=lambda, l1_error))+
geom_line()+
scale_x_log10()+
scale_y_log10() +
facet_wrap(beta_epid/gamma_epid~p_norm)
colnames(res_all)
ggplot(res_all %>% filter(power_pa==1.2,
nb_init == 1), aes(x=lambda, l2_error))+
geom_line()+
scale_x_log10()+
scale_y_log10() +
geom_hline(aes(yintercept = oracle )) +
facet_wrap(beta_epid/gamma_epid~p_norm)
ggplot(res_all %>% filter(power_pa==1.2,
nb_init == 1),
aes(x=lambda, risk_observed))+
geom_line()+
scale_x_log10()+
scale_y_log10() +
geom_hline(aes(yintercept = oracle )) +
facet_wrap(beta_epid/gamma_epid~p_norm)
ggplot(res_all %>% filter(power_pa==1.2,
nb_init == 1),
aes(x=lambda, risk_observed))+
geom_line()+
scale_x_log10()+
scale_y_log10() +
geom_hline(aes(yintercept = oracle )) +
facet_wrap(beta_epid/gamma_epid~p_norm)
ggplot(res_all %>% filter(power_pa==1.2,
nb_init == 1),
aes(x=lambda, l1_error))+
geom_line()+
scale_x_log10()+
scale_y_log10() +
geom_hline(aes(yintercept = oracle )) +
facet_wrap(beta_epid/gamma_epid~p_norm)
library(tidyverse)
setwd("~/Documents/epidemic_modelling/experiments/results/er_graph/")
theme_set(theme_bw(base_size = 14))
folder_path <- "~/Documents/epidemic_modelling/experiments/results/er_graph/"
file_list <- list.files(folder_path, pattern = "^9", full.names = TRUE)
#file_list <- c(file_list, list.files(folder_path, pattern = "^759", full.names = TRUE))
# Read all the files into a single data frame using map_dfr.
data <- map_dfr(file_list, read_csv)
#file_list <- c(file_list, list.files(folder_path, pattern = "^759", full.names = TRUE))
# Read all the files into a single data frame using map_dfr.
#data <- map_dfr(file_list, read_csv)
data_list <- lapply(file_list, function(file) {
data <- read.csv(file, stringsAsFactors = FALSE)
data$filename <- file
return(data)
})
# Combine all individual data frames into one data frame
data <- do.call(rbind, data_list)
colnames(data)
colnames(data)
#### first group by experiment
res  = data %>%
group_by(filename, lambda, beta_epid, gamma_epid, n, proba_er,
steps, heterogeneity_rates, nb_init, p_norm) %>%
summarise_all(mean)
###
res_all  = res %>%
ungroup() %>%
select(-`filename`) %>%
group_by(lambda, beta_epid, gamma_epid, n, proba_er,
steps, heterogeneity_rates, nb_init, p_norm) %>%
summarise_all(mean)
dim(res_all)
unique(res_all$lambda)
unique(res_all$power_pa)
unique(res_all$proba_er)
unique(res_all$beta_epid)
ggplot(res_all %>% filter(power_pa==1.2,
nb_init == 1),
aes(x=lambda, l1_error))+
geom_line()+
scale_x_log10()+
scale_y_log10() +
geom_hline(aes(yintercept = oracle )) +
facet_wrap(beta_epid/gamma_epid~p_norm)
ggplot(res_all %>% filter(
nb_init == 1),
aes(x=lambda, l1_error))+
geom_line()+
scale_x_log10()+
scale_y_log10() +
geom_hline(aes(yintercept = oracle )) +
facet_wrap(beta_epid/gamma_epid~p_norm)
library(tidyverse)
setwd("~/Documents/epidemic_modelling/experiments/results/")
theme_set(theme_bw(base_size = 14))
folder_path <- "~/Documents/epidemic_modelling/experiments/results/dcsbm_graph/"
file_list <- list.files(folder_path, pattern = "^9", full.names = TRUE)
#file_list <- c(file_list, list.files(folder_path, pattern = "^759", full.names = TRUE))
# Read all the files into a single data frame using map_dfr.
#data <- map_dfr(file_list, read_csv)
data_list <- lapply(file_list, function(file) {
data <- read.csv(file, stringsAsFactors = FALSE)
data$filename <- file
return(data)
})
# Combine all individual data frames into one data frame
data <- do.call(rbind, data_list)
colnames(data)
#### first group by experiment
res  = data %>%
group_by(filename, lambda, beta_epid, gamma_epid, n, proba_er,
steps, heterogeneity_rates, nb_init, p_norm) %>%
summarise_all(mean)
